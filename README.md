# ğŸ¤– Jarvis Triage â€” OpenClaw Skill

> Turn any OpenClaw output into a mobile-friendly, voice-first format.  
> Walk and code. Walk and decide. No screen required.

## What is this?

Jarvis Triage is an [OpenClaw](https://github.com/openclaw/openclaw) Skill that compresses long AI outputs into a layered format designed for **voice + AR HUD (4 lines)** interaction. It's the core intelligence layer of the "Jarvis Mode" project â€” enabling you to operate OpenClaw while walking, commuting, or away from your desk.

**Core capability:** Take a 50-line Claude Code plan and turn it into a 30-second voice briefing + key decision points you can approve with one word.

## The Problem

OpenClaw is powerful, but its output is designed for screens â€” Telegram messages, terminal windows, web UIs. When you're away from your computer, you're cut off.

What if you could:
- ğŸš¶ Approve a Claude Code plan while walking to lunch
- ğŸ§ Get a voice briefing of your email analysis during your commute
- ğŸ‘“ See key decision points on AR glasses without stopping

Jarvis Triage makes this possible by acting as an **information compression layer** between OpenClaw's raw output and minimal display interfaces.

## How It Works

### Information Triage (Level 0-4)

| Level | Type | Output | Example |
|-------|------|--------|---------|
| 0 | Silent | Nothing | "Backup completed" |
| 1 | Notify | 1 line | "âœ… Email sent to Zhang San" |
| 2 | Quick Decision | 2-3 lines + options | "Thursday or Friday for the meeting?" |
| 3 | Info Decision | 3-4 lines + voice briefing | "3 vendor quotes compared..." |
| 4 | Plan Review ğŸ”¥ | Structured approval flow | "JWT migration: 7 steps, 2 decisions needed" |

### Plan Review Flow (Level 4)

The killer feature. When Claude Code generates a 50-line implementation plan:

```
You: "Jarvis, triage this plan"

Jarvis (voice): "Auth migration plan, 7 steps. Two decisions needed."

HUD:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”§ JWT Migration (7 steps) â”‚
â”‚ â“ Decision 1/2: Token store â”‚
â”‚   A: Cookie (secure/CORS)   â”‚
â”‚   B: LocalStorage (simple)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

You: "Cookie"

HUD updates â†’ next decision â†’ approve â†’ code runs.
You never stopped walking.
```

## Installation

```bash
# Clone the repo
git clone https://github.com/YOUR_USERNAME/jarvis-triage.git

# Symlink to OpenClaw skills directory
ln -s /path/to/jarvis-triage ~/.openclaw/skills/jarvis-triage

# Start a new OpenClaw session â€” skill loads automatically
```

Or install directly:

```bash
mkdir -p ~/.openclaw/skills
cd ~/.openclaw/skills
git clone https://github.com/YOUR_USERNAME/jarvis-triage.git
```

## Usage

In any OpenClaw channel (Telegram, WhatsApp, etc.):

```
# After any long output
"Jarvis, triage this"

# After a Claude Code plan
"å¸®æˆ‘å®¡æ‰¹ä¸€ä¸‹è¿™ä¸ªplan"

# General summarization
"æ€»ç»“ä¸€ä¸‹"
```

The skill automatically detects content type and applies the appropriate triage level.

## File Structure

```
jarvis-triage/
â”œâ”€â”€ SKILL.md                          # Core skill instructions
â”œâ”€â”€ references/
â”‚   â”œâ”€â”€ triage-levels.md              # Detailed level definitions + edge cases
â”‚   â””â”€â”€ plan-mode-examples.md         # Plan type examples (new feature / refactor / bugfix / QA)
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

## Roadmap

- [x] **Phase 0** â€” Core SKILL.md with Level 0-4 triage logic
- [ ] **Phase 0.5** â€” Real-world testing & prompt iteration
- [ ] **Phase 1** â€” Voice integration (OpenClaw Voice / TTS)
- [ ] **Phase 2** â€” AR HUD integration (Even Realities G1 via AugmentOS SDK)
- [ ] **Phase 3** â€” Auto-triage via AGENTS.md / Hooks (no manual trigger)
- [ ] **Phase 4** â€” Open source "Jarvis Mode" full stack

## Part of Jarvis Mode

This skill is the first building block of a larger vision: **a Jarvis-like interface for OpenClaw** using voice + AR glasses. The full Jarvis Mode stack:

```
Voice Input (AirPods/G1 mic)
    â†“
OpenClaw + Jarvis Triage (this repo)
    â†“
Voice Output (TTS â†’ AirPods) + HUD Output (BLE â†’ AR glasses)
```

Architecture docs and hardware research: coming soon.

## Contributing

This project is in early experimental phase. Issues and PRs welcome â€” especially:

- Real-world triage test results (did the compression lose important info?)
- New plan type examples for `references/plan-mode-examples.md`
- Edge cases where triage level classification fails
- Prompt improvements for SKILL.md

## License

MIT
