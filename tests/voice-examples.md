# Voice Integration Examples

This directory contains examples of voice integration for Jarvis Triage Phase 1.

## Usage Examples

### Example 1: Direct TTS from Triage Output

When a user receives triage output and says "è¯­éŸ³æ’­æŠ¥":

```javascript
// Pseudo-code for SKILL.md execution
if (userMessage.includes('è¯­éŸ³æ’­æŠ¥') || userMessage.includes('read this')) {
    const voiceContent = extractVoiceSection(lastTriageOutput);
    // Returns: "è®¤è¯è¿ç§»è®¡åˆ’å‡ºæ¥äº†ï¼Œåˆ†7æ­¥..."
    
    tts({ text: voiceContent });
    // Output: MEDIA: /path/to/audio.mp3
}
```

### Example 2: Shell Script Integration

```bash
# Extract and speak from a triage file
./voice/parse-and-speak.sh tests/samples/level-4-auth-migration.md

# Expected output:
# ğŸ”Š Speaking: è®¤è¯è¿ç§»è®¡åˆ’å‡ºæ¥äº†ï¼Œåˆ†7æ­¥...
# MEDIA: /tmp/tts-xxx.mp3
```

### Example 3: Voice Trigger Handler

```bash
# Handle "è¯­éŸ³æ’­æŠ¥" command
./voice/voice-trigger.sh speak-last

# This will:
# 1. Find the most recent triage output
# 2. Extract the voice section
# 3. Call TTS tool
```

### Example 4: OpenClaw TTS Tool Direct Usage

```
User: å¸®æˆ‘triageä¸€ä¸‹è¿™ä¸ªplan
[Skill generates triage output with è¯­éŸ³ç‰ˆ section]

User: è¯­éŸ³æ’­æŠ¥
[Skill detects trigger word]

[Skill executes]
tts text='è®¤è¯è¿ç§»è®¡åˆ’å‡ºæ¥äº†ï¼Œåˆ†7æ­¥ã€‚å®‰è£…ä¾èµ–ã€å»ºJWTä¸­é—´ä»¶ã€æ”¹ç™»å½•æ¥å£ã€è¿ç§»æ•°æ®ã€æ”¹å‰ç«¯ã€æ¸…ç†æ—§ä»£ç ã€å†™æµ‹è¯•ã€‚æœ‰ä¸¤ä¸ªéœ€è¦ä½ å†³å®šçš„ï¼Œä¸€ä¸ªæ˜¯tokenå­˜å“ªé‡Œï¼Œä¸€ä¸ªæ˜¯åˆ·æ–°ç­–ç•¥ã€‚å¦å¤–æ•°æ®è¿ç§»é‚£æ­¥ä¸å¯é€†ï¼Œæ‰§è¡Œå‰ä¼šå…ˆå¤‡ä»½ã€‚'

[User hears voice through their audio device]
```

## Sample Voice Content

### Level 4 Plan (Authentication Migration)

**Original Text**:
```
è®¤è¯è¿ç§»è®¡åˆ’å‡ºæ¥äº†ï¼Œåˆ†7æ­¥ã€‚å®‰è£…ä¾èµ–ã€å»ºJWTä¸­é—´ä»¶ã€æ”¹ç™»å½•æ¥å£ã€
è¿ç§»æ•°æ®ã€æ”¹å‰ç«¯ã€æ¸…ç†æ—§ä»£ç ã€å†™æµ‹è¯•ã€‚æœ‰ä¸¤ä¸ªéœ€è¦ä½ å†³å®šçš„ï¼Œ
ä¸€ä¸ªæ˜¯tokenå­˜å“ªé‡Œï¼Œä¸€ä¸ªæ˜¯åˆ·æ–°ç­–ç•¥ã€‚å¦å¤–æ•°æ®è¿ç§»é‚£æ­¥ä¸å¯é€†ï¼Œ
æ‰§è¡Œå‰ä¼šå…ˆå¤‡ä»½ã€‚
```

**Characteristics**:
- ~100 Chinese characters
- ~25 seconds speaking time
- 2 decision points highlighted
- Risk warning included
- Conversational tone

### Level 2 Quick Decision (Meeting Time)

**Original Text**:
```
ä¼šè®®æ—¶é—´ç¡®è®¤ï¼Œå‘¨å››ä¸‹åˆ2ç‚¹æˆ–è€…å‘¨äº”ä¸Šåˆ10ç‚¹ï¼Œé€‰å“ªä¸ªï¼Ÿ
```

**Characteristics**:
- ~25 Chinese characters
- ~5 seconds speaking time
- Clear options presented
- Question format

## Testing Commands

```bash
# Make scripts executable
chmod +x voice/*.sh

# Run voice demo
./voice/parse-and-speak.sh --demo

# Test with sample files
for sample in tests/samples/level-*.md; do
    echo "Testing: $sample"
    ./voice/parse-and-speak.sh "$sample" --quiet
done

# Full voice test suite
./tests/scripts/test-voice.sh
```

## Expected TTS Output Format

When the TTS tool is called, it returns:

```
MEDIA: /path/to/generated/audio/file.mp3
```

This media reference is automatically handled by OpenClaw and sent to the appropriate channel (Telegram voice message, WhatsApp audio, etc.)

## Voice Content Guidelines

### Do's âœ“

- Use conversational Chinese (å£è¯­åŒ–)
- Keep under 30 seconds (100-120 characters)
- Include decision count ("æœ‰ä¸¤ä¸ªéœ€è¦ä½ å†³å®šçš„")
- Warn about risks ("æ•°æ®è¿ç§»ä¸å¯é€†")
- Use natural pauses (commas for breathing)

### Don'ts âœ—

- Technical jargon without explanation
- Abbreviations (JWT â†’ "è®¤è¯ä»¤ç‰Œ")
- Bullet points or lists
- Code snippets
- URLs or file paths

### Example Conversion

**Before** (screen format):
```
Steps:
1. Install jsonwebtoken
2. Create middleware
3. Update routes
```

**After** (voice format):
```
ä¸€å…±7æ­¥ã€‚å®‰è£…ä¾èµ–ã€å»ºä¸­é—´ä»¶ã€æ”¹ç™»å½•æ¥å£ã€è¿ç§»æ•°æ®ã€æ”¹å‰ç«¯ã€æ¸…ç†æ—§ä»£ç ã€æœ€åå†™æµ‹è¯•ã€‚
```
